{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T09:48:31.510615Z",
     "start_time": "2020-06-14T09:48:31.506619Z"
    }
   },
   "source": [
    "# Introduction au Reinforcement Learning #2 #\n",
    "\n",
    "Seconde partie de notre petit introduction au reinforcement learning. On a vu dans la première partie une manière intuitive d'entrainer un agent à résoudre un jeu de morpion que l'on pourrait appliquer à d'autres jeu ou d'autres scénarios mais il est temps de mettre un peu de théorie.\n",
    "\n",
    "*Ok mais juste un peu hein ?*\n",
    "\n",
    "Ok ok vraiment juste ce qu'il faut pour avancer. Promis."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un peu de théorie ##\n",
    "\n",
    "Reprenons les bases. De quoi avons nous besoins ? D'un **agent** et d'un **environnement**. Quel est le but de l'agent ? De parcourir l'environnement, d'apprendre et de trouver le parcours optimal.\n",
    "\n",
    "*ok... ça reste assez vague là, non ?*\n",
    "\n",
    "Oui mais on va illustrer ça avec un peu de code pour mieux comprendre. Commençons par définir un environnement. Imaginons un carré découpé en 9 cases. (un peu comme notre grille de Morpion)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Là c'est un environnement **très très simple** et completement **connu** (un environnement pourrait être partielement connu voir inconnu) pour illustrer mais bien entendu on peu avoir des environnements beaucoup plus compliqué. Rien que pour notre jeu du Morpion l'environnement sera tous les coups possibles !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T06:18:32.753577Z",
     "start_time": "2020-06-21T06:18:32.740581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0], [0, 0, 0], [0, 0, 0]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de notre environnement de base\n",
    "def create_env(size):\n",
    "    '''Create a square empty environnement\n",
    "    -size : number of case in line'''\n",
    "    return [[0 for i in range(size)] for j in range(size)]\n",
    "\n",
    "# Il est constitué de 3 lignes de 3 cases que l'on peu définir avec une liste comme ci-dessous\n",
    "env = create_env(3)\n",
    "        \n",
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous pouvons mettre un agent dans notre environnement et le faire explorer. Notre agent sera simplement représenté par les coordonnées d'une case. On sera donc où il se trouve dans l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:05:35.189806Z",
     "start_time": "2020-06-21T13:05:35.177837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boris se trouve sur la case à l'intersection de la ligne 0 et de la colonne 1 de notre environnement.\n"
     ]
    }
   ],
   "source": [
    "# Appelons notre ami Boris et plongeons le dans l'environnement au hasard\n",
    "import random\n",
    "random.seed(777)\n",
    "\n",
    "boris = (random.randint(0, 2), random.randint(0,2))\n",
    "\n",
    "print('Boris se trouve sur la case à l\\'intersection de la ligne', boris[0], 'et de la colonne', boris[1], 'de notre environnement.')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ0AAACXCAYAAAAPvVmwAAAIY0lEQVR4Ae2dMW8bRxCF9dvyM/wD8h9cpXLlXqnSpnCVSkAKI4CEFEEAA0aQNEkRpoiBAAEC2DBDSacNqMgibzmre3M7sztHPgOCyb3dN4/zvtsjKQo8S/zHDjTuwFnjeizHDiRCRwiad4DQNW85CxI6MtC8A0Xozs7OEn/Yg1oGJKIJHU8u182F0BEwV8CkXZHQETpCJ50ZHDuu55HVO50kEHFMAvezFx/SEn4k7xF7LHlCvateSEiFIo5JD34JwG09St4j9ljyhHondMF2QDQ4KfTeY6h3QkfozFgldNkrVV5ezdgqChE6QleEw+sAoSN0XmwVdQkdoSvC4XWA0BE6L7aKuoSO0BXh8DpA6Mygu0krNKUhpc36Lq1+u04vzuf9BgQNDrXUch7qne/TTb5Pp4BuP+GbIV280oOHBrdfKspt1Duh84JuS8KH2/RyUn8MJhpcFND2faDeCd0kFDN3uoc0fv1hDNXUm9RocPthR7mNeid0WujWt+lLcc3H9Py7m7RajxF4//tG9ekWNLhxlRj3UO+ETgRof3fKdroidA9rroa02WOA0O014+EmoTOG7tmPw6jL735Zc6cbdSSV/9ga3SozvRB3Je9Tz6XKx8Gd7nydXn5/m97d7LVgGNLF1/u75vRtyfueYuibqHfudNqdThH76q1ul9uCjwansNFsKuqd0HlAd3OXLl9/VF1WP+20aHDNSFIUQr0TOg/otkENd2n10yY9m9QfX3LR4BQsNJuKeid0k1Bkz+mUEWovsWhwShtNpqPeCZ0WutJbJufr9MW31+nyr7txwMOQvlH8HhYNblwkxj3UO6Gzgu5RZ5PeZG8Q/3w1voR+ev4m/Y8GFwOzsQvUO6F7hKUERnZ5Le10jzqH0K3elrQPx9HgxnHHuId6J3SPsBwC8P9OhEP3+atNuvgzu7ymu/TmdUn7cBwNLgZmYxeod0KnhW7c5+l7myF9NVljBx8a3HTh9jNQ74RuEohsp1NmyV+DHTaM0DlC9/cf1+n5pP5ul9teztHd4jDK/iOod0I3CYVup9tsUnr/z5Aur/5VvzFM6LK/MdhSvJR/0hknvT0RcUzyvuS+S96LJB3bg48ImOTp2PpO6CYvpePnVxIU3mOELrvEStRGHJOC84bFSl/yHrHHkifUOy+vwXY/NDgp9N5jqHdCR+jMWCV02VMDq8uftw4anBkphkKod+503OnMsCN03OnMYEKFCB2hQ1kxm+cCnSTKseP6shHrPCWiVc/prA1R7/iBJXTZJZfQ+0NP6Aid+NEpz5OP0BG65UEnURtxTDpzI/qUPJ2Cd9ULCalJEcdOIbgl953QBUvvFE4YQkfozDqAnjCEzqzlNkJocDbVbFVQ74TOtu/Vamhw1YUcBFDvhM6h+TWSaHA1NbzWot4JnVcCM3XR4GbKuy5DvRM61xj04mhwemX/Fah3QuefhaoCGpxKtNFk1DuhaxQIWgYNDtVrOQ/1TuhapgLUQoMDpJpPQb0TuubRPF0QDe5plT5HUe+Erk8+xapocEWBjgdQ74SuY0hSaTQ4aW3vMdQ7oeudVFYfDS5bFuIu6p3QhYhrZwINbrcizi3UO6GLk9m9EzS4YLZV3gldsPQIXfY3BcHyKdo5heCKD77jAbTv3Ok6hiSVRoOT1vYeQ70Tut5JZfXR4LJlIe6i3gldiLh2JtDgdivi3EK9E7o4md07QYMLZlvlndAFS4/Q8dVrcyQJHaEjdIoOoCcML6+KpraYigbXwou2Buqd0Gk76zwfDc7Zxix51Duhm9Vev0VocH4O5iuj3gnd/B67rESDcyleKYp6J3SVjbZejgZnXddCD/VO6Cy6baiBBmdY0kwK9U7ozFpuI4QGZ1PNVgX1Tuhs+16thgZXXchBAPVO6ByaXyOJBldTw2st6p3QeSUwUxcNbqa86zLUO6FzjUEvjganV/ZfgXondP5ZqCqgwalEG01GvRO6RoGgZdDgUL2W81DvKugkUY75f9XRknssQU/oso9vLTngiN4JHQFb3tc0RTyT6Cn25Z07HXe65e10ErURx6TdL6JPydMpeFe9kJCaFHHsFIJbct8JXbD0TuGEIXSEzqwD6AlD6MxabiOEBmdTzVYF9U7obPterYYGV13IQQD1Tugcml8jiQZXU8NrLeqd0HklMFMXDW6mvOsy1Duhc41BL44Gp1f2X4F6J3T+WagqoMGpRBtNRr0TukaBoGXQ4FC9lvNQ74SuZSpALTQ4QKr5FNQ7oWsezdMF0eCeVulzFPVO6PrkU6yKBlcU6HgA9U7oOoYklUaDk9b2HkO9E7reSWX10eCyZSHuot4JXYi4dibQ4HYr4txCvRO6OJndO0GDC2Zb5Z3QBUuP0GV/UxAsn6KdUwiu+OA7HkD7zp2uY0hSaTQ4aW3vMdQ7oeudVFYfDS5bFuIu6p3QhYhrZwINbrcizi3UO6GLk9m9EzS4YLZV3gldsPQIHV+9NkeS0BE6QqfoAHrC8PKqaGqLqWhwLbxoa6DeCZ22s87z0eCcbcySR70Tulnt9VuEBufnYL4y6p3Qze+xy0o0OJfilaKod0JX2Wjr5Whw1nUt9FDvhM6i24YaaHCGJc2kUO+EzqzlNkJocDbVbFVQ74TOtu/Vamhw1YUcBFDvhM6h+TWSaHA1NbzWot4JnVcCM3XR4GbKuy5DvRM61xj04mhwemX/Fah3QuefhaoCGpxKtNFk1DuhaxQIWgYNDtVrOQ/1roJOEuVY7G+s6Z2PBD2hyz6+1TukY6tP6AjY8r6m6djOQj4e/6cG3Om408Xe6SRCOcYOWHSg+ELCQpwa7IDUAUIndYVjrh0gdK7tpbjUAUIndYVjrh0gdK7tpbjUgf8Ax7Ho1PVEAtIAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà notre agent infiltré Boris se trouve donc là :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "*Cool !*\n",
    "\n",
    "Maintenant faut dire à notre agent de se déplacer pour **explorer** l'environnement. Mais comme il est un peu bête-bête, il va falloir lui dire comment faire. Pour ça on va lui donner une rêgle de déplacement qu'on appelera **POLICY** représenté par le symbole **π**.\n",
    "\n",
    "*Ooooh... Mais comment qu'on fait ça concrétement ?*\n",
    "\n",
    "Ah et bien libre à vous, on parle de théorie là faut que ça s'adapte à toutes les situation et sytèmes.\n",
    "\n",
    "*Mais euh... Chais pas moi :(*\n",
    "\n",
    "Ok ok. On va définir une policy pour notre agent pour donner un exemple. Qu'est-ce qu'on pourrait faire ? ... On a qu'à dire tout simplement que notre agent peut se déplacer dans n'importe quelle direction de façon aléatoire avec la même proba. Comme notre environnement nous impose de nous déplacer de droite à gauche ou de haut en bas (Bon j'avoue c'est moi qui vient de décider que l'environnement fonctionne comme ça !), notre agent aura 0.25 chance d'aller dans une direction. On aurait pu choisir une autre rêgle, genre il a 80% de chance d'aller vers le bas ou quand il fait beau il va en haut et quand il fait gris il va en bas ! Encore une fois on est libre (pour l'instant...)\n",
    "\n",
    "Allez, programmons notre policy pour notre agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:36:26.876751Z",
     "start_time": "2020-06-21T13:36:26.856786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvel emplacement de Boris : (0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Créons une fonction de déplacement qui suit la policy définie\n",
    "def deplacement(limit, position, direction=-1, probability=1):\n",
    "    '''fonction de deplacement de l'agent\n",
    "    - limit : taille limite de l'env. où se trouve l'agent\n",
    "    - position : position de l'agent (tuple)\n",
    "    - direction : direction choisie de l'agent (int)\n",
    "    - probability : probabilité de l'agent d'aller dans la bonne direction\n",
    "    '''\n",
    "    if direction == -1 :\n",
    "        direction = random.randint(0,3)\n",
    "    elif random.random() > probability:\n",
    "        directions = [d for d in range(4)]\n",
    "        directions.remove(direction)\n",
    "        direction = random.choice(directions)\n",
    "            \n",
    "    if direction == 0 and position[0] - 1 >= 0: # déplacement vers le haut si possible\n",
    "        new_position = (position[0] - 1, position[1])\n",
    "    elif direction == 1 and position[1] + 1 < limit: # déplacement vers la droite\n",
    "        new_position = (position[0], position[1] + 1)\n",
    "    elif direction == 2 and position[0] + 1 < limit: # déplacement vers le bas\n",
    "        new_position = (position[0] + 1, position[1])\n",
    "    elif direction == 3 and position[1] - 1 >= 0: # déplacement vers la gauche\n",
    "        new_position = (position[0], position[1] - 1)\n",
    "    else:\n",
    "        # Déplacement impossible\n",
    "        new_position = False\n",
    "    return new_position\n",
    "\n",
    "# Déplaçons Boris selon notre policy\n",
    "random.seed(777)\n",
    "boris = deplacement(len(env), boris)\n",
    "\n",
    "print('Nouvel emplacement de Boris :', boris)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà notre agent s'est déplacé selon la policy et se retrouve là :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "On peut continuer comme ça et faire **explorer** l'environnement en entier par l'agent. Bon comme ça, ça sert pas à grand chose. Boris peut se déplacer indéfinement dans l'environnement mais là il apprend rien.\n",
    "\n",
    "*Bah oui il est un peu nul l'environnement. Faudrait y rajouter des trucs qui puissent intéresser Boris.*"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui du coup on va étoffer un peu notre environnement. Voyons voir...\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Voilà ! Maintenant il y a des sous-sous dans une des cases et un danger dans une autre. Du coup on peut echainer sur la notion de **récompense** (**reward**), on peut dire que si Boris arrive sur la case \"$\" il obtient une **récompense positive** et si il tombe dans la case \"!\", là il obtient une **récompense négative**.\n",
    "\n",
    "Du coup maintenant, Boris à un but noble et beau : amasser le plus de pognon !!!\n",
    "\n",
    "*Bon c'est bien gentil mais comment on traduit ça en code ?*\n",
    "\n",
    "Bonne question et bien donnons une valeur à nos \"$\" et \"!\". Par la même occasion on va mettre zéro pour les cases neutres, sans récompense ni danger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T06:18:43.051003Z",
     "start_time": "2020-06-21T06:18:43.043004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1], [0, 0, -1], [0, 0, 0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modification de l'environnement\n",
    "new_env = create_env(3)\n",
    "\n",
    "new_env[0][2] = 1\n",
    "new_env[1][2] = -1\n",
    "\n",
    "new_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon maintenant on peut faire évoluer Boris dans l'environnement et voir combien de pépettes il peut récupérer ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T06:18:45.365664Z",
     "start_time": "2020-06-21T06:18:45.344664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'exploration de Boris.\n",
      "Gains de Boris : -34 $\n"
     ]
    }
   ],
   "source": [
    "# On donne une tirelire à Boris où mettre ses sous\n",
    "tirelire = 0 # Elle est vide au début off course\n",
    "\n",
    "# On fait une boucle pour laisser Boris explorer 100 fois l'environnement\n",
    "exploration = 100\n",
    "while exploration > 0:\n",
    "    boris = (2, 0) # Par commodité on lâche Boris toujours au même endroit\n",
    "    explore = True\n",
    "    while explore:\n",
    "        pi = random.randint(0,3) # On reprend notre policy\n",
    "        \n",
    "        # Boris se déplace\n",
    "        new_boris = deplacement(3, boris)\n",
    "        if new_boris:\n",
    "            boris = new_boris\n",
    "            \n",
    "        # On récupère la valeur de la case et on la met dans sa poche\n",
    "            tirelire += new_env[boris[0]][boris[1]]\n",
    "        \n",
    "        # On vérifie si l'exploration est terminée (arrivé sur la case \"$\" ou \"!\")\n",
    "        if boris == (0, 2) or boris == (1, 2):\n",
    "            explore = False\n",
    "            \n",
    "    exploration -= 1\n",
    "    \n",
    "print(\"Fin de l'exploration de Boris.\")\n",
    "print(\"Gains de Boris :\", tirelire, \"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WHAAAAAT !! Mais il a pas du tout gagner d'argent le Boris !*\n",
    "\n",
    "Oui on voit bien qu'il est plus souvent tombé sur la case piège que sur la case gain. Et c'est normal au vu de la case de départ et de la policy (déplacement aléatoire). Notre **policy** n'est donc pas optimale.\n",
    "\n",
    "*Comment avoir une meilleure policy ?*\n",
    "\n",
    "Et bien il faut que notre agent puisse déterminer la **valeur** de ses déplacements, de ses **actions**. Il va nous falloir un nouveau concept théorique. Dites bonjour à la **Value Function** !"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAACaCAYAAAAuLkPmAAAJoElEQVR4Ae2dr28cVxDH7884GlipoGEJDWukgFoyKS+oDA2tksoKqKyCKLCoksNCKqUgkksq2cz9D1xQYFBgEGBQMNXZN3ezv252596bfZP3jVS9t/t2Z773nc++vb27+i0I/+DAjA4sZsyN1HCAACAgmNUBADir/UgOAMHArA4AwFntR3IACAZmdQAAzmo/kg8CuFgsCP/Bg30Z0C4xAIgLLetEAwABWFbAtBkSAAJAAKhdJRj/fN9rJp0BtWCljPcBXYo2TUdt2ic9hGjmlTJeWxEj+w4AS6neWkdtFw8ABIDJHLBcPAAwmf1pAlmKmCbz/lEs2gHg/r4njWApYlIBewSzaAeAexie41RLEXPosMS0aAeAFqcznmMpYkY5k0JbtAPASRbnP9hSxPyqxmWwaAeA47x1O8pSRDdxSiKLdgComOo9bCmit8ahfBbt8wH43y1dvDmil18uH78sX35BL79/Sxe3Qy9v/H6LEeOjE1Fk7eKF3n88puX6xxqnV2LA2LX4Pg+A99f09tUavPavVZYv6PTq3mjB42kWI0YnjKxdvsi7Czr5avsjiKoAvP75+e6fCD07o2tp1sR+TgAja9/Y+Pd7Onq2hW/lVz0A3l/QyZJf/FM6/m19z739QMfiijz+aJ8FswEYWfuKvrsb+vDTAT1p33WqAvDqdPO+Y3F4TvIt3+27g+3M+MPl5oKd2skGYGTtdEvnh3zhL2ixfE7PxQVfzQwoIVu+bt1o/zqjp3x1fnNON1PJWx+fC8DI2kkAuHx1Spf/3jSArAbAyx+3V+HBOzn/EdE/53TAAC5OyToH5gIwsvYVgO+/+5bOfr+hu4cLtTkjAsCVKQBw+xZkcyEOflBhvD/waQCQds+Ax3RhfA6ZfwYsTztjt20BoAIgbsF8IW2hSdkDgACwhyeGTrY9hyXYVSmAN79uP2qJ9hQcWXuX2EoBpD9Ptm+0v/6l8VGL/JhjUeLngJG1dwisFcC7D3S0ecJrfhNysvl6aEknfxifQIi2gG/yJHqSjKwdALID93T9Oup3wZG1s//c1joDrl7/p2s6i/prmMjamb2HtmYAHwy4o8s3R3Tw7MnjLTPS7wEpsnamsHoA2Yj0rfwIg/vps+SJyHplmydT+qhSM/e1LIPvzjmAbLVgpYxLzdwvRZumg/XKVjunlHGpmfuaNgCoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftaMACoOeQ8zoWTrbMEczqpmftasEkAclC02/+1FF7s9gIAih+lApbdsOTwBwACwN5fiOeArS8mAASAALDvysA+/9vhHJ4nnQG1YKWM9xldijZNR23aJz0Fa+aVMl5bESP7DgBLqd5aR20XDwAEgMkcsFw8ADCZ/WkCWYqYJvP+USzaAeD+vieNYCliUgF7BLNoB4B7GJ7jVEsRc+iwxLRoB4AWpzOeYyliRjmTQlu0A8BJFuc/2FLE/KrGZbBoB4DjvHU7ylJEN3FKIot2AKiY6j1sKaK3xqF8Fu3zARh5wb/I2ofoIaJ9Fy+MA2DkBf8ia98BHyVYvDAMgJEX/IusfZC/RIsXxgAw8oJ/kbX30Zd48cIYAEZe8C+y9g6AzT9QmWLxwhAAyr+EH22ZhsjaO/xlWLwwBICRF/yLrL0PwNSLFwLAtcsWI7oF6u75vABsv77mLdmyeqbFd/fPAccXsbwF/yJrb+PW3QaAWK415yI7XeJaewAgAEwIoHxgatwaD8+ptUz4GsRKAIy84F8k7QCwNcFvNiMv+BdIOwDcENfqRF7wL7L2Vhm6m5XcgokiL/gXWXsXueaeagDEYoXNwje3Gg8M679r0zwi11ZNAD54GHnBv8jahwCuDsAhI/bfP98sAu1t7zVH3L8J0QSlGG+bsNqO8q827YOVqc2IUgCtzXcAWAp5ax0AsFIjSuEQAALAWVkEgAAQABodsFw8eA9oNDvXaZYi5tIyNa5FOwCc6nLm4y1FzCxpdHiLdgA42l6fAy1F9FGmZ7FoB4C6r65HWIroKnBHMot2ALjD0DmGLEWcQ2dfTov2SQD2JcC+Ohacsda5D1S5DwBiKa+sS3lJ2Pr6ABAAAkDr9I7zyr/99816ch9mQMyAcWZASW7J/b6ZsWS9Ultt2ifNgNKokvu1FbGUWlh8B4ClVG+tw1LEUl6CRTsALKV6ALBZCQvNzQjzbUH7PN5bfMcMOE+tBrNaijgYzHnAoh0AOhdJS2cpohbTa9yiHQB6VWdkHksRR4bOfphFOwDMXpZpCSxFnJYh39EW7QAwXz1MkS1FNCXKcJJFOwDMUIh9QlqKuE++lOdatM8HYOQF/6C9l9s4AEZe8A/ae+Fb7QwDYOQF/6B9kL8gAEZe8A/ah+kLMwNGXvAP2uMDKP96OxYr7NbT8j6qG6W7p1Tf3Z+Cxy93dUqXXR9H7clVRGjfbb/FdwC429PGKABs2NHZ+MwAxGKFXNBOpQ07xl88vr5jBpxQzPFFxNuHsRcPAASAsy4S6Q5gpAX/2mxCe9uR5jbPerJtHtHdcgeQAi3417EL2juWyB0SPO7L8b6+P4CRF/yD9j6GNvsYOtluBgc6/gBiscKBUjzulsXj/s4TRg+WudDiDABiscJdzDB0st11/KSxT9d09mrZ+6OBxfIFnV7dTwrXPlhq5n77mPb2PAA+qIi84B+0t0FabTN0su07Tu6bEUApI21fGsD9tBnyRWO9ss2XLW1kqZn7WgYAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WjAAqDnkPM6Fk62zBHM6qZn7WrBJAHJQtOWvUFRKjQAgVkLq/ZWKF6AAEAACQK+rDXnKe2uAGRAzYMwZUCMX43AghQODT8EpgiMGHNAcAICaQxjP6gAAzGovgmsOAEDNIYxndQAAZrUXwTUH/gcgT13XBWQ27wAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un peu plus de théorie ##\n",
    "\n",
    "La **Value Function** sert à determiner la **valeur d'un état et/ou d'une action**. Pour déterminer ces valeurs on va retropropager la récompense dans l'environnement. Ainsi Boris poura \"obtenir/voir\" une partie de la récompense selon ses déplacements. Intuitivement cela correspond à donner une valeur plus grande au déplacement qui se rapproche de la récompense.\n",
    "\n",
    "La value function va calculer l'espérance de gain de tous les états de l'environnement.\n",
    "\n",
    "Allez comme vous aimez les maths :\n",
    "\n",
    "$$ v(s) = E [G_{t} | S_{t} = s] $$\n",
    "$$ G_{t} = \\sum_{k=0}^{\\infty} \\gamma^{k}R_{t+k+1}$$\n",
    "$s$ = état, $t$ = temps, $\\gamma$ = discount factor (coefficient d'actualisation), $G$ = Fonction de gain, $R$ = récompense\n",
    "\n",
    "Bon allez ! Ralez pas, c'était juste pour vous embêter ;) En gros, ça dit juste que la value function à l'état \"s\" est l'éspérance (la moyenne) des gains futurs.\n",
    "\n",
    "Et pour simplifier les choses on va utiliser l'**équation de Bellman** qui est la version récurrente de la value function.\n",
    "\n",
    "$$ v(s) = E [R_{t+1} + \\gamma.v(S_{t+1}) | S_t = s]$$\n",
    "\n",
    "*Salaud !*\n",
    "\n",
    "Mais non, mais non pas d'inquiétude on va tout comprendre en calculant la value fonction pour notre petit environnement. Donc pour rappel notre environnement ressemble à ça pour l'agent :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Et l'agent se déplace selon une politique random soit toutes les directions ont la même probabilité. Calculons la value function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:04:17.140748Z",
     "start_time": "2020-06-21T14:04:17.088780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul de l'état (case) : (0, 0) : ( 0 + 0 + 0 + 0 ) /  4  =  0.0\n",
      "Calcul de l'état (case) : (0, 1) : ( 0 + 1 + 0 + 0 ) /  4  =  0.25\n",
      "Calcul de l'état (case) : (1, 0) : ( 0 + 0 + 0 + 0 ) /  4  =  0.0\n",
      "Calcul de l'état (case) : (1, 1) : ( 0 + -1 + 0 + 0 ) /  4  =  -0.25\n",
      "Calcul de l'état (case) : (2, 0) : ( 0 + 0 + 0 + 0 ) /  4  =  0.0\n",
      "Calcul de l'état (case) : (2, 1) : ( 0 + 0 + 0 + 0 ) /  4  =  0.0\n",
      "Calcul de l'état (case) : (2, 2) : ( -1 + 0 + 0 + 0 ) /  4  =  -0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.25, 1], [0.0, -0.25, -1], [0.0, 0.0, -0.25]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comme c'est un peu compliqué de la calculer d'un seul coup on va calculer une première fois pour chaque case (état)\n",
    "# Et on va faire une fonction pour ne pas à recommencer d'écrire le code à chaque fois ^^\n",
    "# On ajoute aussi quelques arguments qui nous servirons plus tard\n",
    "def VF(env, end_state, if_out, proba=1, policy='random', info=False):\n",
    "    '''Calcul la value function pour un etat\n",
    "    - env : environnement (listxlist)\n",
    "    - end_state : les états de fin (gain ou perte) (listxtuple)\n",
    "    - if_out : comportement si direction en dehors de l'environnement (None ou int)\n",
    "    - proba : probabilité du déplacement choisi (float{0,1})\n",
    "    - policy : les choix de déplacement ('random' ou listxlist == env.size)\n",
    "    - info : pour afficher les étapes de calcul (boolean)\n",
    "    '''\n",
    "    v = [ligne.copy() for ligne in env]\n",
    "    v_new = [ligne.copy() for ligne in env]\n",
    "    size = len(env)\n",
    "    for ligne in range(size):\n",
    "        for colonne in range(size):\n",
    "            # On vérfie qu'on est pas sur une case de fin\n",
    "            if (ligne, colonne) not in end_state:\n",
    "                # On prend la valeur de la case selon la direction si elle existe\n",
    "                haut = v[ligne-1][colonne] if ligne > 0 else if_out\n",
    "                bas = v[ligne+1][colonne] if ligne < size - 1 else if_out\n",
    "                droite = v[ligne][colonne+1] if colonne < size - 1 else if_out\n",
    "                gauche = v[ligne][colonne-1] if colonne > 0 else if_out\n",
    "            \n",
    "                # on actualise la valeur moyenne de la case de notre value function (à l'exception des case '$' et '!')\n",
    "                directions = [haut, droite, bas, gauche]\n",
    "                if policy == 'random':\n",
    "                    directions = [v for v in directions if v is not None] # On retire les directions impossibles si existe\n",
    "                    v_new[ligne][colonne] = sum(directions) / len(directions)\n",
    "                else:\n",
    "                    v_direction = directions.pop(policy[ligne][colonne]) # On récupère la valeur de la direction de la policy\n",
    "                    directions = [v for v in directions if v is not None]\n",
    "                    v_new[ligne][colonne] = v_direction * proba + sum(directions) * (1 - proba) / len(directions)\n",
    "                \n",
    "                # Print les étapes si spécifié\n",
    "                if info:\n",
    "                    print(\"Calcul de l'état (case) :\", (ligne, colonne), ': (', \\\n",
    "                          haut, '+', droite, '+', bas, '+', gauche, ') / ', len(directions), ' = ', v_new[ligne][colonne])\n",
    "    return v_new\n",
    "\n",
    "v1 = VF(new_env, [(0,2), (1,2)], 0, info=True)\n",
    "\n",
    "v1"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc voilà, pour chaque case nous avons calculé la moyenne des gains/valeurs que l'on peut obtenir pour chaque directions à partir de cette case.\n",
    "\n",
    "on a calculé : $ v(s_t) = E[v(s_{t+1})] $\n",
    "\n",
    "*Hé mais il manque le $R$ et le $\\gamma$ !*\n",
    "\n",
    "Le $R$ on le calcul que lorsqu'on arrive sur une case de fin (cas particulier de notre environnement) donc c'est normal et le $\\gamma$, c'est une valeur qu'on utilise pour atténuer l'influence des états proportionnelement de l'état actuel. En gros cela veut dire qu'on accorde plus d'importance dans le process de décision aux états proches. En tout cas pas trés utile pour notre exemple et du coup ici le on $\\gamma = 1$ dans la pratique on le mets souvent à $0,9$.\n",
    "\n",
    "Résultat :\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "*Hé mais c'est super !!! Mais ça sert à quoi ?*\n",
    "\n",
    "Attends, c'est pas fini. Pour avoir la Value Function réelle, il faut itérer ce process une infinité de fois !\n",
    "\n",
    "*What ! Mais c'est n'importe quoi !*\n",
    "\n",
    "Oui bon ok, l'infini c'est pas atteignable. Du coup faut choisir une stratégie pour se rapprocher au plus près de la VF réelle sans que ce soit trop pénalisant d'un point de vu ressources. Il y'en a plusieurs, par exemple on peut regarder si l'écart entre les mises à jour des valeurs devient très petit. Mais en général on atteint des valeurs acceptables bien avant car finalement l'important c'est d'avoir des valeurs qui représente bien l'intéret d'une case par rapport aux autres, peu importe la valeur exacte qu'elle devrait avoir... C'est pas clair ?\n",
    "\n",
    "Bon recommençons notre process 2 ou 3 fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:04:48.885486Z",
     "start_time": "2020-06-21T14:04:48.865477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0625, 0.1875, 1], [-0.0625, -0.1875, -1], [0.0, -0.125, -0.25]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[0.03125, 0.21875, 1],\n",
       " [-0.03125, -0.25, -1],\n",
       " [-0.046875, -0.109375, -0.28125]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v2 = VF(v1, [(0,2), (1,2)], 0)\n",
    "display(v2)\n",
    "\n",
    "v3 = VF(v2, [(0,2), (1,2)], 0)\n",
    "display(v3)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat :\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:05:03.026546Z",
     "start_time": "2020-06-21T14:05:02.782545Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.030844881537773806, 0.1935628073312472, 1],\n",
       " [-0.07018328118015198, -0.25659365221278496, -1],\n",
       " [-0.054984354045596776, -0.1497541350022351, -0.2874385337505588]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour le fun\n",
    "v_old = [ligne.copy() for ligne in v3]\n",
    "\n",
    "for x in range(10000): # presque l'infini non ?\n",
    "    v_new = VF(v_old, [(0,2), (1,2)], 0)\n",
    "    v_old = [ligne.copy() for ligne in v_new]\n",
    "\n",
    "v_new"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "On voit que l'odre des cases par valeurs est le même après 10000 itération que celui après 3 itérations. Dans la pratique, l'infini n'est pas nécessaire.\n",
    "\n",
    "*Ok super mais encore une fois, ça sert à quoi ?*\n",
    "\n",
    "Et bien justement ça sert à **évaluer notre policy**. En effet si on avait eu un policy différente la VF aurait été différente également.\n",
    "\n",
    "Maintenant, roulement de tambour ... **brbrbrbrbrbrbrbrbr** ... Nous pouvons en déduire le chemin **optimal** !! Et donner une nouvelle policy à Boris !! Une **optimal policy** que nous nommerons **π**\n",
    "\n",
    "*Ooooh Show me the money !!*\n",
    "\n",
    "Yes, on se calme. Il suffit de dire à notre de se déplacer en fonction des valeurs de la value function. Allons'y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:05:14.000685Z",
     "start_time": "2020-06-21T14:05:13.984690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1], [0, 0, -1], [0, 3, 3]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D'abord on définit notre optimal policy avec notre v_new (ou v3 ça marche aussi ^^)\n",
    "def optimal_policy(vf, end_state):\n",
    "    '''définit notre optimal policy\n",
    "    - vf : résultat de la value function ou policy evaluation (listxlist)\n",
    "    '''\n",
    "    size = len(vf)\n",
    "    policy = [ligne.copy() for ligne in vf]\n",
    "    for ligne in range(size):\n",
    "        for colonne in range(size):\n",
    "            if (ligne, colonne) not in end_state:\n",
    "                haut = vf[ligne-1][colonne] if ligne > 0 else None\n",
    "                bas = vf[ligne+1][colonne] if ligne < size - 1 else None\n",
    "                droite = vf[ligne][colonne+1] if colonne < size - 1 else None\n",
    "                gauche = vf[ligne][colonne-1] if colonne > 0 else None\n",
    "\n",
    "                directions = [haut, droite, bas, gauche]\n",
    "                dir_true = [v for v in directions if v is not None] # On retire les directions impossibles si existe\n",
    "                policy[ligne][colonne] = directions.index(max(dir_true))\n",
    "            else:\n",
    "                policy[ligne][colonne] = vf[ligne][colonne]\n",
    "                \n",
    "    return policy\n",
    "\n",
    "v_pi = optimal_policy(v_new, [(0,2), (1,2)])\n",
    "\n",
    "v_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:05:21.963686Z",
     "start_time": "2020-06-21T14:05:21.951657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'exploitation GREEDY de l'environnement par Boris.\n",
      "Gains de Boris : 100 $\n"
     ]
    }
   ],
   "source": [
    "# Reprenons Boris avec sa tirelire vide (on est gentil on efface sa dette précédente)\n",
    "tirelire = 0\n",
    "\n",
    "size = len(new_env)\n",
    "# Boris va une nouvelle parcourir 100 fois l'env.\n",
    "exploration = 100\n",
    "while exploration > 0:\n",
    "    boris = (2, 0) # Par commodité on lâche Boris toujours au même endroit\n",
    "    explore = True\n",
    "    while explore:\n",
    "        # Boris se déplace avec sa nouvelle policy\n",
    "        boris = deplacement(size, boris, v_pi[boris[0]][boris[1]])\n",
    "        if boris == (0, 2) or boris == (1, 2):\n",
    "            tirelire += new_env[boris[0]][boris[1]] # on lui donne sa récompense\n",
    "            explore = False\n",
    "            \n",
    "    exploration -= 1\n",
    "    \n",
    "print(\"Fin de l'exploitation GREEDY de l'environnement par Boris.\")\n",
    "print(\"Gains de Boris :\", tirelire, \"$\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Boris est riche !!!*\n",
    "\n",
    "Ouais d'ailleurs faut pas trop le laisser se balader dans l'environnement là, ou sinon je vais être ruiné !\n",
    "\n",
    "Voilà nous avons permis à Boris de **plannifier** un parcours optimal pour avoir sa récompense. Si on détail sa nouvelle policy elle ressemblera à ça :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Petit rappel de ce que l'on a vu :\n",
    "- Agent\n",
    "- Environnement\n",
    "- Policy\n",
    "- Value Function\n",
    "- Equation de Bellman\n",
    "\n",
    "Ce que nous avons fait c'est une **POLICY EVALUATION** qui nous a permis de **PLANNIFIER** une **OPTIMAL POLICY**. Cette solution n'est pas appliquable à toutes les situations.\n",
    "Ses limites :\n",
    "- On doit connaitre entièrement l'environnement ou le **modèle** qui caractérise l'environnement. C'est un **model base algorythm**\n",
    "- Elle ne permet pas d'obtenir la meilleur policy dans tous les environnement.\n",
    "\n",
    "Mais nous allons avoir qu'il y'a des moyens d'améliorer tout ça :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encore plus de Théorie !##\n",
    "\n",
    "*Encore ?! On en a soupé là. Quand est-ce qu'on revient à notre jeu de Morpion ?*\n",
    "\n",
    "Et bien j'aimerais bien aussi :( Mais il faut comprendre que notre simple jeu de Morpion a un environnement plus complexe qu'il n'y parait. Bien que théoriquement on puisse déterminer tous les états possible du jeu, le nombre est assez élevé et du coup pas évident à mettre en place avec notre théorie d'apprentissage actuelle.\n",
    "\n",
    "Du coup je prospose qu'on étoffe un peu notre grille actuelle pour complexifié un peu le problème.\n",
    "\n",
    "On va faire grossir notre environnement de 5 cases ! Il fera donc 8x8 cases ! On va aussi rajouté plus de cases pièges disons 4 répartis aléatoirement et on va perturber le comportement de Boris !\n",
    "\n",
    "*Hein comment on va faire ça ?*\n",
    "\n",
    "Bah on va faire boire Boris jusqu'à ce qu'il soit assez saoul pour qu'il ne maîtrise pas bien ces mouvements. Ainsi quand il vaudra aller dans une direction, il aura une probabilité non nulle d'aller dans une autre direction ! Voilà qui devrait bien complexifier notre environnement et l'apprentissage de Boris.\n",
    "\n",
    "*Mouais C'est pas très éthique tout ça !*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:08:17.746329Z",
     "start_time": "2020-06-21T14:08:17.734324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, -1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, -1],\n",
       " [0, 0, 0, 0, 0, -1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, -1, 0, 1]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du nouvel environnement\n",
    "gros_env = create_env(8)\n",
    "\n",
    "# Ajout de pièges\n",
    "random.seed(777)\n",
    "for p in range(4):\n",
    "    gros_env[random.randint(0,7)][random.randint(0,7)] = -1\n",
    "    \n",
    "# Ajout des sous-sous\n",
    "gros_env[7][7] = 1\n",
    "\n",
    "gros_env"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà notre nouvel environnement :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Maintenant appliquons notre stratégie élaborée précedement avec notre Boris bourré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:08:21.222496Z",
     "start_time": "2020-06-21T14:08:21.210504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 7), (3, 7), (4, 5), (7, 5), (7, 7)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On va faire une petit fonction pour récupérer les états de fin\n",
    "def etats_fin(env):\n",
    "    ef = []\n",
    "    for ligne in range(len(gros_env)):\n",
    "        for colonne in range(len(gros_env)):\n",
    "            if gros_env[ligne][colonne] != 0:\n",
    "                ef.append((ligne, colonne))\n",
    "    return ef\n",
    "\n",
    "etats_fin = etats_fin(gros_env)\n",
    "\n",
    "etats_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:54:58.609096Z",
     "start_time": "2020-06-21T14:54:58.589096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 3, 2, 2, 2, 0, None],\n",
       " [3, 3, 2, 0, 0, 0, 2, 0],\n",
       " [0, 2, 2, 2, 0, 1, 2, 1],\n",
       " [3, 0, 2, 1, 0, 2, 3, None],\n",
       " [0, 3, 1, 0, 3, None, 2, 1],\n",
       " [3, 0, 3, 1, 3, 0, 3, 2],\n",
       " [2, 1, 0, 1, 0, 0, 0, 3],\n",
       " [2, 2, 0, 1, 0, None, 3, None]]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Et une autre pour créer une policy au hasard\n",
    "def policy(env, end_state):\n",
    "    '''définit une policy au hasard\n",
    "    - env : l'environnement pour notre policy (listxlist)\n",
    "    - end_state : liste des états de fin (listextuple)\n",
    "    '''\n",
    "    size = len(env)\n",
    "    policy = [ligne.copy() for ligne in env]\n",
    "    for ligne in range(size):\n",
    "        for colonne in range(size):\n",
    "            if (ligne, colonne) not in end_state:\n",
    "                policy[ligne][colonne] = random.randint(0, 3)\n",
    "            else:\n",
    "                policy[ligne][colonne] = None\n",
    "    return policy\n",
    "\n",
    "random.seed(777)\n",
    "\n",
    "pi0 = policy(gros_env, etats_fin)\n",
    "\n",
    "pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:55:06.205097Z",
     "start_time": "2020-06-21T14:55:04.465129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9999934670211585, -0.9999920028273606, -0.999975641930425, -0.9998858758788071, -0.9998334853869062, -0.9997357732008805, -0.9999387989238786, -1]\n",
      "[-0.9999934670211585, -0.9999920028273606, -0.999975641930425, -0.9998858758788071, -0.9998334853869062, -0.9997357732008805, -0.9999387989238786, -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1, -0.99, -0.99],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.99, -0.87],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97, -0.83],\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0, -1, -0.86, 1]]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimons notre VF avec Boris bourré\n",
    "v_new = [ligne.copy() for ligne in gros_env]\n",
    "\n",
    "for t in range(10000): # 10000 cycle chosit arbitrairement mais ça devrait largement converger\n",
    "    v_old = [ligne.copy() for ligne in v_new]\n",
    "    v_new = VF(v_old, etats_fin, -1, 0.8, pi0) # -1 si la direction choisie est impossible pour décourager Boris d'aller dans le mur\n",
    "    if t >= 9998:\n",
    "        print(v_new[0]) # pour comparer et determiner si ça converge bien\n",
    "    \n",
    "vf_gros_env = [ligne.copy() for ligne in v_new]\n",
    "\n",
    "[[round(v,2) for v in ligne] for ligne in vf_gros_env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:55:13.623108Z",
     "start_time": "2020-06-21T14:55:13.611106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2, 1, 1, 2, 2, -1],\n",
       " [1, 1, 2, 2, 1, 2, 2, 3],\n",
       " [1, 1, 1, 1, 1, 1, 2, 3],\n",
       " [1, 1, 1, 2, 2, 1, 2, -1],\n",
       " [1, 1, 1, 2, 2, -1, 2, 2],\n",
       " [1, 2, 1, 2, 1, 1, 1, 2],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2],\n",
       " [1, 1, 1, 0, 0, -1, 1, 1]]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de notre nouvelle optimal policy\n",
    "pi1 = optimal_policy(vf_gros_env, etats_fin)\n",
    "pi1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bah à ça à l'air bon non ? On peut s'arrêter là.*\n",
    "\n",
    "Et bien on va tester.\n",
    "\n",
    "- Boris ! Viens je t'invite à prendre un verre !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut balancer notre Boris saoul dans l'environnement et voir comment il se débrouille avec sa nouvelle policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:55:45.781216Z",
     "start_time": "2020-06-21T14:55:45.765215Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'exploration de Boris.\n",
      "Gains de Boris saoul : 64 $\n"
     ]
    }
   ],
   "source": [
    "random.seed(777)\n",
    "\n",
    "tirelire = 0 # Bah oui il est saoul ! Il a tout dépenser dans l'alcool\n",
    "exploration = 100\n",
    "size = len(gros_env)\n",
    "while exploration > 0:\n",
    "    boris = (0, 0)\n",
    "    explore = True\n",
    "    while explore:\n",
    "        mouv = deplacement(len(gros_env), boris, pi1[boris[0]][boris[1]], 0.8)\n",
    "        if mouv != False:\n",
    "            boris = mouv \n",
    "        if boris in etats_fin:\n",
    "            tirelire += gros_env[boris[0]][boris[1]]\n",
    "            explore = False\n",
    "            \n",
    "    exploration -= 1\n",
    "    \n",
    "print(\"Fin de l'exploration de Boris.\")\n",
    "print(\"Gains de Boris saoul :\", tirelire, \"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ah ouais le Boris bourré est moins efficace !*\n",
    "\n",
    "Du coup on peut se demander s'il y a une autre policy possible qui soit plus efficace pour le Boris bourré. Alors comment on fait ça ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration ##\n",
    "\n",
    "*Oh non qu'est ce que c'est que ça :(*\n",
    "\n",
    "Le mieux c'est de décrire l'algo directement je crois :\n",
    "1. On determine une policy **π** arbitraire\n",
    "2. On calcul les valeurs d'état selon π\n",
    "3. On determine la policy qui max nos gain avec cette value function\n",
    "4. Si cette dernière policy est différente de la policy d'avant on recommence\n",
    "\n",
    "Bon c'est pas trés clair comme ça j'en convient. Essayons de mettre ça en pratique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:00:38.988601Z",
     "start_time": "2020-06-21T15:00:37.436601Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013670217606366539, 0.16363622559137062, 0.25678231234856375, 0.09724149041923173, 0.15325192952964772, 0.23818512149516924, 0.15682541070828548, -1]\n",
      "[0.013670217606366539, 0.16363622559137062, 0.25678231234856375, 0.09724149041923173, 0.15325192952964772, 0.23818512149516924, 0.15682541070828548, -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.16, 0.26, 0.1, 0.15, 0.24, 0.16, -1],\n",
       " [0.24, 0.36, 0.38, 0.36, 0.34, 0.36, 0.34, 0.15],\n",
       " [0.29, 0.4, 0.4, 0.38, 0.37, 0.37, 0.37, 0.18],\n",
       " [0.41, 0.53, 0.55, 0.56, 0.43, 0.3, 0.39, -1],\n",
       " [0.45, 0.57, 0.59, 0.59, 0.44, -1, 0.52, 0.44],\n",
       " [0.43, 0.55, 0.6, 0.6, 0.55, 0.54, 0.66, 0.67],\n",
       " [0.41, 0.56, 0.59, 0.61, 0.63, 0.65, 0.8, 0.83],\n",
       " [0.11, 0.27, 0.37, 0.47, 0.4, -1, 0.72, 1]]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reprenons la dérnière policy de Boris et evaluons là\n",
    "random.seed(777)\n",
    "\n",
    "# Estimons notre VF avec Boris bourré\n",
    "v_new = [ligne.copy() for ligne in gros_env]\n",
    "\n",
    "for t in range(10000):\n",
    "    v_old = [ligne.copy() for ligne in v_new]\n",
    "    v_new = VF(v_old, etats_fin, -1, 0.8, pi1)\n",
    "    if t >= 9998:\n",
    "        print(v_new[0])\n",
    "    \n",
    "v1_gros_env = [ligne.copy() for ligne in v_new]\n",
    "\n",
    "[[round(v,2) for v in ligne] for ligne in v1_gros_env]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:01:37.552768Z",
     "start_time": "2020-06-21T15:01:37.544759Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 2, 2, 2, 2, -1],\n",
       " [1, 2, 2, 2, 2, 2, 2, 3],\n",
       " [2, 2, 2, 2, 2, 1, 2, 3],\n",
       " [1, 2, 2, 2, 3, 3, 2, -1],\n",
       " [1, 1, 2, 2, 3, -1, 2, 2],\n",
       " [1, 1, 1, 2, 2, 1, 2, 2],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2],\n",
       " [0, 0, 0, 0, 0, -1, 1, 1]]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On définit notre nouvelle policy à partir de v1\n",
    "pi2 = optimal_policy(v1_gros_env, etats_fin)\n",
    "\n",
    "pi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:01:50.118686Z",
     "start_time": "2020-06-21T15:01:50.110681Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On checke si pi_new == pi_old\n",
    "pi1 == pi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nouvelle policy diffère de la précédente, du coup on recommence le process jusqu'à trouver le policy optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:04:09.061294Z",
     "start_time": "2020-06-21T15:04:07.473288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reprenons la dérnière policy de Boris et evaluons là\n",
    "random.seed(777)\n",
    "\n",
    "v_new = [ligne.copy() for ligne in gros_env]\n",
    "for t in range(10000):\n",
    "    v_old = [ligne.copy() for ligne in v_new]\n",
    "    v_new = VF(v_old, etats_fin, -1, 0.8, pi2)\n",
    "\n",
    "v2_gros_env = [ligne.copy() for ligne in v_new]\n",
    "\n",
    "# On définit notre nouvelle policy à partir de v2\n",
    "pi3 = optimal_policy(v2_gros_env, etats_fin)\n",
    "\n",
    "# On compare les policy\n",
    "pi3 == pi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:19:46.631262Z",
     "start_time": "2020-06-21T15:19:43.583207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 False\n",
      "5 True\n",
      "nombre d'itérations : 5\n",
      "policy optimale :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 2, 2, 2, 2, -1],\n",
       " [1, 2, 2, 2, 2, 3, 3, 3],\n",
       " [1, 1, 2, 2, 3, 3, 3, 3],\n",
       " [1, 1, 2, 3, 3, 3, 2, -1],\n",
       " [1, 1, 2, 2, 2, -1, 2, 2],\n",
       " [1, 1, 1, 1, 2, 1, 2, 2],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2],\n",
       " [1, 0, 0, 0, 0, -1, 1, 1]]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On recommence temps que les policy ne sont pas identiques\n",
    "v_new = [ligne.copy() for ligne in v2_gros_env]\n",
    "pi_new = [ligne.copy() for ligne in pi3]\n",
    "pi_old = [ligne.copy() for ligne in pi2]\n",
    "\n",
    "i = 3\n",
    "\n",
    "while pi_old != pi_new:\n",
    "    i += 1\n",
    "    pi_old = [ligne.copy() for ligne in pi_new]\n",
    "    v_new = [ligne.copy() for ligne in gros_env]\n",
    "    for t in range(10000):\n",
    "        v_old = [ligne.copy() for ligne in v_new]\n",
    "        v_new = VF(v_old, etats_fin, -1, 0.8, pi_old)\n",
    "\n",
    "    v_old = [ligne.copy() for ligne in v_new]\n",
    "\n",
    "    pi_new = optimal_policy(v_new, etats_fin)\n",
    "\n",
    "    print(i, pi_old == pi_new)\n",
    "\n",
    "optimal_pi = pi_new\n",
    "\n",
    "print('nombre d\\'itérations :', i)\n",
    "print('policy optimale :')\n",
    "optimal_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hourra ! On y est arrivé cette fois ! ... N'est ce pas ?*\n",
    "\n",
    "Ah... oui, normalement ^^ Mais bon vaut mieux vérifier en live. Rebalançons notre Boris bourré dans l'environnement pour voir ce qu'il récolte avec notre nouvelle policy.\n",
    "\n",
    "_Va vraiment faire plus attention à Boris, on risque d'avoir des plaintes de la ligue de protections des Boris..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:26:37.375716Z",
     "start_time": "2020-06-21T15:26:37.355720Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la ballade optimale du Boris saoul.\n",
      "Gains de Boris: 74 $\n"
     ]
    }
   ],
   "source": [
    "random.seed(777)\n",
    "\n",
    "tirelire = 0 # Par soucis d'équité des tests scientifiques, on lui a piqué tous ses précédents gains.\n",
    "exploration = 100 # Comme d'hab\n",
    "size = len(gros_env)\n",
    "\n",
    "while exploration > 0:\n",
    "    boris = (0, 0)\n",
    "    explore = True\n",
    "    while explore:\n",
    "        mouv = deplacement(len(gros_env), boris, optimal_pi[boris[0]][boris[1]], 0.8)\n",
    "        if mouv != False:\n",
    "            boris = mouv \n",
    "        if boris in etats_fin:\n",
    "            tirelire += gros_env[boris[0]][boris[1]]\n",
    "            explore = False\n",
    "            \n",
    "    exploration -= 1\n",
    "    \n",
    "print(\"Fin de la ballade optimale du Boris saoul.\")\n",
    "print(\"Gains de Boris:\", tirelire, \"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ooooooh... **+10$**  C'est pas mal du tout !!*\n",
    "\n",
    "*...*\n",
    "\n",
    "*Est-ce qu'on ose demander...*\n",
    "\n",
    "Quoi ?\n",
    "\n",
    "*Ce... Ce serait possible de faire encore mieux ?*\n",
    "\n",
    "**Argh quoi !? Vous en voulez encore !!!** J'en était sûr que vous finiriez par aimer la théorie (bon on a pas ma pratiqué là c'est vrai) Et bien, on peut faire un autre algo : la **VALUE ITERATION**\n",
    "\n",
    "*Hum... Autant, on comprend l'intêret de la **Policy Iteration** mais la **Value Iteration**...*\n",
    "\n",
    "Attendez que je vous explique ce que c'est au moins !\n",
    "\n",
    "Allez go !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration ##\n",
    "\n",
    "En fait c'est assez simple, on se dit que dès la première itération de l'estimation de notre Value Function pour une policy, la nouvelle policy que l'on peut obtenir de cette estimation très parcellaire de notre VF est au pire équivalente à l'ancienne polic, et au mieux elle est meilleure. Du coup on peut modifier notre policy à chaque itération de notre VF et théoriquement converger plus vite.\n",
    "\n",
    "Allez, petite formule pour faire plaisir ^^\n",
    "\n",
    "$$ v_{k+1}(s) = max_a E[r_{t+1} + \\gamma.v_{k}(s_{t+1})|s_t = s, a_t = a] $$\n",
    "\n",
    "*AAAAARGH !!! NOOOOON !!!!*\n",
    "\n",
    "Hé ! On se calme c'est quasiment la même que la dernière fois ! On a juste rajouté des $k$ et $k+1$ juste pour dier qu'à chaque étape on prend l'action $max$ de l'espérance de nos gains afin de pouvoir en définir une policy à chaque itération.\n",
    "\n",
    "Bon allez, ça suffit, on y va, ça sera plus simple bande de grognons !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:24:40.773251Z",
     "start_time": "2020-06-21T17:24:40.745253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -1],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, -0.07, -0.07, -1],\n",
       " [0.0, 0.0, 0.0, 0.0, -0.07, -1, -0.07, -0.1],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, -0.07, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, -0.07, 0.0, 0.8],\n",
       " [0.0, 0.0, 0.0, 0.0, -0.1, -1, 0.7, 1]]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bon d'abord on va créer une fonction VF spéciale Value Iteration\n",
    "def VF_VI(env, end_state, if_out, proba=1):\n",
    "    '''Calcul la value function pour un etat\n",
    "    - env : environnement (listxlist)\n",
    "    - end_state : les états de fin (gain ou perte) (listxtuple)\n",
    "    - if_out : comportement si direction en dehors de l'environnement ('out' ou int)\n",
    "    - proba : probabilité du déplacement choisi (float{0,1})\n",
    "    '''\n",
    "    v = [ligne.copy() for ligne in env]\n",
    "    v_new = [ligne.copy() for ligne in env]\n",
    "    size = len(env)\n",
    "    for ligne in range(size):\n",
    "        for colonne in range(size):\n",
    "            if (ligne, colonne) not in end_state:\n",
    "                haut = v[ligne-1][colonne] if ligne > 0 else if_out\n",
    "                bas = v[ligne+1][colonne] if ligne < size - 1 else if_out\n",
    "                droite = v[ligne][colonne+1] if colonne < size - 1 else if_out\n",
    "                gauche = v[ligne][colonne-1] if colonne > 0 else if_out\n",
    "                directions = [haut, droite, bas, gauche]\n",
    "\n",
    "                directions = [v for v in directions if v != 'out']\n",
    "                valeurs = [((proba*(len(directions)-1)-(1-proba))*v+(1-proba)*sum(directions))/(len(directions)-1) for v in directions]\n",
    "                v_new[ligne][colonne] = max(valeurs)\n",
    "\n",
    "    return v_new\n",
    "\n",
    "# On reprend notre gros_env et appliquons une fois la value fonction en prenant les max\n",
    "v1_vi = VF_VI(gros_env, etats_fin, 'out', 0.8)\n",
    "\n",
    "[[round(v, 2) for v in ligne] for ligne in v1_vi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:30:25.070793Z",
     "start_time": "2020-06-21T17:30:21.554790Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal value function :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.79, 0.79, 0.79, 0.79, 0.79, 0.77, 0.59, -1],\n",
       " [0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.76, 0.56],\n",
       " [0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.75, 0.56],\n",
       " [0.79, 0.79, 0.79, 0.79, 0.77, 0.65, 0.65, -1],\n",
       " [0.79, 0.79, 0.79, 0.78, 0.67, -1, 0.78, 0.75],\n",
       " [0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.94, 0.96],\n",
       " [0.79, 0.79, 0.79, 0.79, 0.79, 0.81, 0.96, 0.99],\n",
       " [0.79, 0.79, 0.79, 0.77, 0.61, -1, 0.8, 1]]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On boucle jusqu'à s'approche d'une VF optimale\n",
    "v_vi_new = [ligne.copy() for ligne in v1_vi]\n",
    "\n",
    "t = 1\n",
    "while t < 10000:\n",
    "    v_vi_old = [ligne.copy() for ligne in v_vi_new]\n",
    "    v_vi_new = VF_VI(v_vi_old, etats_fin, 'out', 0.8)\n",
    "    t += 1\n",
    "    \n",
    "print('optimal value function :')\n",
    "[[round(v, 2) for v in ligne] for ligne in v_vi_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:32:48.672361Z",
     "start_time": "2020-06-21T17:32:48.660365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 3, 3, 3, 3, 3, -1],\n",
       " [2, 3, 3, 3, 3, 3, 3, 3],\n",
       " [2, 3, 3, 3, 3, 3, 3, 3],\n",
       " [2, 3, 3, 3, 3, 0, 2, -1],\n",
       " [2, 2, 3, 3, 2, -1, 2, 2],\n",
       " [2, 2, 2, 2, 2, 1, 2, 2],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2],\n",
       " [0, 0, 0, 0, 0, -1, 1, 1]]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y'a plus qu'à faire notre optimal policy\n",
    "vi_pi = optimal_policy(v_vi_new, etats_fin)\n",
    "\n",
    "vi_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:35:45.458864Z",
     "start_time": "2020-06-21T17:35:45.442896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de parcours pour Boris... Il en peut plus le pauvre.\n",
      "Gains de Boris: 80 $\n"
     ]
    }
   ],
   "source": [
    "# plus qu'à tester ^^\n",
    "# Allez qu'on m'amène Boris et qu'on lui bourre la gueule ! (pov Boris :( ...)\n",
    "random.seed(777)\n",
    "\n",
    "tirelire = 0 # Qui a encore piqué les sous de Boris ! ça suffit maintenant !\n",
    "exploration = 100\n",
    "size = len(gros_env)\n",
    "\n",
    "while exploration > 0:\n",
    "    boris = (0, 0)\n",
    "    explore = True\n",
    "    while explore:\n",
    "        mouv = deplacement(len(gros_env), boris, vi_pi[boris[0]][boris[1]], 0.8)\n",
    "        if mouv != False:\n",
    "            boris = mouv \n",
    "        if boris in etats_fin:\n",
    "            tirelire += gros_env[boris[0]][boris[1]]\n",
    "            explore = False\n",
    "            \n",
    "    exploration -= 1\n",
    "    \n",
    "print(\"Fin de parcours pour Boris... Il en peut plus le pauvre.\")\n",
    "print(\"Gains de Boris:\", tirelire, \"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OOOOOOOH !!! IL A ENCORE GAGNE PLUS !!!***\n",
    "*Doit être content finalement le Boris :) Et cette fois on lui laisse les sous hein ?*\n",
    "Oui, oui promis on le laisse tranquille maintenant.\n",
    "\n",
    "Bon on se fait un petit recap ?\n",
    "\n",
    "|Algo               |Gains  |Différence  |\n",
    "|:-----------------:|:---:|:----------:|\n",
    "|Policy Improvement |64\\$|   |\n",
    "|Policy Iteration   |74\\$|+10|\n",
    "|Value Iteration    |80\\$|+16|\n",
    "\n",
    "Je ne sais pas vous mais je trouve ça beau ^^\n",
    "\n",
    "Bon on a mérité notre pause !\n",
    "\n",
    "A bientôt pour de futures aventures avec Boris dans l'univers du **Reinforcement Learning**\n",
    "\n",
    "Bye bye ^^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
